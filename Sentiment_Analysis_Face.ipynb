{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KHonqAHYGODZ",
    "outputId": "9b63cd95-8cea-46e1-dd9d-c389a68cfa12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9MK0StRYDQrd",
    "outputId": "f5f04caf-b27b-4f28-fe15-9b7a005bf0b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3472 images belonging to 7 classes.\n",
      "Found 802 images belonging to 7 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 46, 46, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 46, 46, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 44, 44, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 44, 44, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 22, 22, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 22, 22, 64)        0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 20, 20, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 20, 20, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 18, 18, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 18, 18, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 9, 9, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 9, 9, 128)         0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 7, 7, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 7, 7, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 5, 5, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 5, 5, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 2, 2, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 2, 2, 256)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               262400    \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 7)                 1799      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,394,183\n",
      "Trainable params: 1,391,943\n",
      "Non-trainable params: 2,240\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "34/54 [=================>............] - ETA: 2:48 - loss: 2.9485 - accuracy: 0.1617"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2f05229a1ee6>\u001b[0m in \u001b[0;36m<cell line: 144>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;31m# Training the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Defining the emotion labels\n",
    "emotion_labels = {\n",
    "    0: 'Angry',\n",
    "    1: 'Disgust',\n",
    "    2: 'Fear',\n",
    "    3: 'Happy',\n",
    "    4: 'Sad',\n",
    "    5: 'Surprise',\n",
    "    6: 'Neutral'\n",
    "}\n",
    "\n",
    "# Defining the image dimensions and number of classes\n",
    "img_height = 48\n",
    "img_width = 48\n",
    "num_classes = 7\n",
    "\n",
    "# Defining the directories for the training and test data\n",
    "train_dir = '/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/FER-2013/train'\n",
    "test_dir = '/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/FER-2013/test'\n",
    "\n",
    "# Loading the training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=64,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "# Loading the test data\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=64,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "# Defining the model architecture\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(256, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Add a convolutional layer with 32 filters, 3x3 kernel size, and relu activation function\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
    "# Add a batch normalization layer\n",
    "model.add(BatchNormalization())\n",
    "# Add a second convolutional layer with 64 filters, 3x3 kernel size, and relu activation function\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "# Add a second batch normalization layer\n",
    "model.add(BatchNormalization())\n",
    "# Add a max pooling layer with 2x2 pool size\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Add a dropout layer with 0.25 dropout rate\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Add a third convolutional layer with 128 filters, 3x3 kernel size, and relu activation function\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "# Add a third batch normalization layer\n",
    "model.add(BatchNormalization())\n",
    "# Add a fourth convolutional layer with 128 filters, 3x3 kernel size, and relu activation function\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "# Add a fourth batch normalization layer\n",
    "model.add(BatchNormalization())\n",
    "# Add a max pooling layer with 2x2 pool size\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Add a dropout layer with 0.25 dropout rate\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Add a fifth convolutional layer with 256 filters, 3x3 kernel size, and relu activation function\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
    "# Add a fifth batch normalization layer\n",
    "model.add(BatchNormalization())\n",
    "# Add a sixth convolutional layer with 256 filters, 3x3 kernel size, and relu activation function\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
    "# Add a sixth batch normalization layer\n",
    "model.add(BatchNormalization())\n",
    "# Add a max pooling layer with 2x2 pool size\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Add a dropout layer with 0.25 dropout rate\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Flatten the output of the convolutional layers\n",
    "model.add(Flatten())\n",
    "# Add a dense layer with 256 neurons and relu activation function\n",
    "model.add(Dense(256, activation='relu'))\n",
    "# Add a seventh batch normalization layer\n",
    "model.add(BatchNormalization())\n",
    "# Add a dropout layer with 0.5 dropout rate\n",
    "model.add(Dropout(0.5))\n",
    "# Add a dense layer with 7 neurons (one for each class) and softmax activation function\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "# Compile the model with categorical cross-entropy loss, adam optimizer, and accuracy metric\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer= tf.keras.optimizers.Adam(lr=0.001), metrics=['accuracy'])\n",
    "\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# # Compiling the model\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# define the ModelCheckpoint callback to save the model weights after each epoch\n",
    "checkpoint_callback = ModelCheckpoint('fer2013_model_weights_0.h5', save_weights_only=True, save_best_only=True)\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.n // train_generator.batch_size,\n",
    "    epochs=50,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.n // test_generator.batch_size,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "\n",
    "# Evaluating the model on the test set\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=0)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# Saving the model\n",
    "model.save('fer2013_model_0.h5')\n",
    "model.save_weights('fer2013_model_weights_0.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZOaf4CHhdj8E",
    "outputId": "25b94894-785d-411f-bacf-d3653ce844be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3472 images belonging to 7 classes.\n",
      "Found 802 images belonging to 7 classes.\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_11 (Conv2D)          (None, 46, 46, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 46, 46, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 44, 44, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 44, 44, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 22, 22, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 22, 22, 64)        0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 20, 20, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 20, 20, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 18, 18, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 18, 18, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 9, 9, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 9, 9, 128)         0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 7, 7, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 7, 7, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 5, 5, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 5, 5, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 2, 2, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 2, 2, 256)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               262400    \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 7)                 1799      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,394,183\n",
      "Trainable params: 1,391,943\n",
      "Non-trainable params: 2,240\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 91/110\n",
      "27/27 [==============================] - 199s 7s/step - loss: 0.9784 - accuracy: 0.6373 - val_loss: 1.3466 - val_accuracy: 0.5326\n",
      "Epoch 92/110\n",
      "27/27 [==============================] - 124s 5s/step - loss: 0.9601 - accuracy: 0.6447 - val_loss: 1.3385 - val_accuracy: 0.5312\n",
      "Epoch 93/110\n",
      "27/27 [==============================] - 128s 5s/step - loss: 0.9849 - accuracy: 0.6268 - val_loss: 1.3221 - val_accuracy: 0.5391\n",
      "Epoch 94/110\n",
      "27/27 [==============================] - 129s 5s/step - loss: 0.9591 - accuracy: 0.6447 - val_loss: 1.3377 - val_accuracy: 0.5286\n",
      "Epoch 95/110\n",
      "27/27 [==============================] - 162s 6s/step - loss: 0.9672 - accuracy: 0.6453 - val_loss: 1.3448 - val_accuracy: 0.5378\n",
      "Epoch 96/110\n",
      "27/27 [==============================] - 123s 5s/step - loss: 0.9567 - accuracy: 0.6391 - val_loss: 1.3519 - val_accuracy: 0.5299\n",
      "Epoch 97/110\n",
      "27/27 [==============================] - 127s 5s/step - loss: 0.9439 - accuracy: 0.6549 - val_loss: 1.3149 - val_accuracy: 0.5299\n",
      "Epoch 98/110\n",
      "27/27 [==============================] - 129s 5s/step - loss: 0.9452 - accuracy: 0.6429 - val_loss: 1.3294 - val_accuracy: 0.5273\n",
      "Epoch 99/110\n",
      "27/27 [==============================] - 126s 5s/step - loss: 0.9435 - accuracy: 0.6507 - val_loss: 1.3442 - val_accuracy: 0.5260\n",
      "Epoch 100/110\n",
      "27/27 [==============================] - 127s 5s/step - loss: 0.9529 - accuracy: 0.6603 - val_loss: 1.3544 - val_accuracy: 0.5326\n",
      "Epoch 101/110\n",
      "27/27 [==============================] - 126s 5s/step - loss: 0.9376 - accuracy: 0.6495 - val_loss: 1.3758 - val_accuracy: 0.5065\n",
      "Epoch 102/110\n",
      "27/27 [==============================] - 125s 5s/step - loss: 0.9396 - accuracy: 0.6525 - val_loss: 1.3364 - val_accuracy: 0.5273\n",
      "Epoch 103/110\n",
      "27/27 [==============================] - 126s 5s/step - loss: 0.9329 - accuracy: 0.6645 - val_loss: 1.3426 - val_accuracy: 0.5286\n",
      "Epoch 104/110\n",
      "27/27 [==============================] - 128s 5s/step - loss: 0.9629 - accuracy: 0.6417 - val_loss: 1.3561 - val_accuracy: 0.5182\n",
      "Epoch 105/110\n",
      "27/27 [==============================] - 124s 5s/step - loss: 0.9291 - accuracy: 0.6394 - val_loss: 1.3464 - val_accuracy: 0.5299\n",
      "Epoch 106/110\n",
      "27/27 [==============================] - 125s 5s/step - loss: 0.9455 - accuracy: 0.6513 - val_loss: 1.3727 - val_accuracy: 0.5221\n",
      "Epoch 107/110\n",
      "27/27 [==============================] - 125s 5s/step - loss: 0.9399 - accuracy: 0.6483 - val_loss: 1.3720 - val_accuracy: 0.5169\n",
      "Epoch 108/110\n",
      "27/27 [==============================] - 125s 5s/step - loss: 0.9342 - accuracy: 0.6579 - val_loss: 1.3638 - val_accuracy: 0.5195\n",
      "Epoch 109/110\n",
      "27/27 [==============================] - 123s 5s/step - loss: 0.9320 - accuracy: 0.6648 - val_loss: 1.3832 - val_accuracy: 0.5143\n",
      "Epoch 110/110\n",
      "27/27 [==============================] - 134s 5s/step - loss: 0.9474 - accuracy: 0.6522 - val_loss: 1.3931 - val_accuracy: 0.5130\n",
      "Test accuracy: 0.5137156844139099\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Defining the emotion labels\n",
    "emotion_labels = {\n",
    "    0: 'Angry',\n",
    "    1: 'Disgust',\n",
    "    2: 'Fear',\n",
    "    3: 'Happy',\n",
    "    4: 'Sad',\n",
    "    5: 'Surprise',\n",
    "    6: 'Neutral'\n",
    "}\n",
    "\n",
    "# Defining the image dimensions and number of classes\n",
    "img_height = 48\n",
    "img_width = 48\n",
    "num_classes = 7\n",
    "\n",
    "# Defining the directories for the training and test data\n",
    "train_dir = '/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/FER-2013/train'\n",
    "test_dir = '/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/FER-2013/test'\n",
    "\n",
    "# Loading the training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=128,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "# Loading the test data\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=128,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "# Creating an instance of the trained model\n",
    "model = load_model('/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/Models/fer2013_model_1.2.h5')\n",
    "\n",
    "# Load the weights for your model\n",
    "model.load_weights('/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/Models/fer2013_model_weights_1.2.h5')\n",
    "\n",
    "# Compile the model with categorical cross-entropy loss, adam optimizer, and accuracy metric\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer= tf.keras.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# define the ModelCheckpoint callback to save the model weights after each epoch\n",
    "checkpoint_callback = ModelCheckpoint('fer2013_model_weights_1.3.h5', save_weights_only=True, save_best_only=True)\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.n // train_generator.batch_size,\n",
    "    epochs=110,\n",
    "    initial_epoch=90,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.n // test_generator.batch_size,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "\n",
    "# Evaluating the model on the test set\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=0)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# Saving the model\n",
    "model.save('/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/Models/fer2013_model_1.3.h5')\n",
    "model.save_weights('/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/Models/fer2013_model_weights_1.3.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bvKC0ZKOmKbh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g-0LMZT2mKj3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JRi9qzwcmKmp",
    "outputId": "a4bfca82-adda-4a52-b1e6-adc81cc2998f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2781 images belonging to 7 classes.\n",
      "Found 691 images belonging to 7 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 1s 0us/step\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 48, 48, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 54, 54, 3)    0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 24, 24, 64)   9472        ['conv1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 24, 24, 64)   256         ['conv1_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 24, 24, 64)   0           ['conv1_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 26, 26, 64)   0           ['conv1_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 12, 12, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 12, 12, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 12, 12, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 12, 12, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 12, 12, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 12, 12, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 12, 12, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 12, 12, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 12, 12, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 12, 12, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 12, 12, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 12, 12, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 12, 12, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 12, 12, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 12, 12, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 12, 12, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 12, 12, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 12, 12, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 12, 12, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 12, 12, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 12, 12, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 12, 12, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 12, 12, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 12, 12, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 12, 12, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 12, 12, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 12, 12, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 12, 12, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 12, 12, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 6, 6, 128)    32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 6, 6, 128)    147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 6, 6, 512)    131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 6, 6, 512)    66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 6, 6, 512)    0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 6, 6, 512)    0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 6, 6, 128)    65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 6, 6, 128)    147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 6, 6, 512)    66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 6, 6, 512)    0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 6, 6, 512)    0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 6, 6, 128)    65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 6, 6, 128)    147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 6, 6, 512)    66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 6, 6, 512)    0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 6, 6, 512)    0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 6, 6, 128)    65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 6, 6, 128)    147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 6, 6, 512)    66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 6, 6, 512)    0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 6, 6, 512)    0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 3, 3, 256)    131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 3, 3, 256)    590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 3, 3, 1024)   525312      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 3, 3, 1024)   263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 3, 3, 1024)   0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                                                  'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 3, 3, 1024)   0           ['conv4_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 3, 3, 256)    262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 3, 3, 256)    590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 3, 3, 1024)   263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 3, 3, 1024)   0           ['conv4_block1_out[0][0]',       \n",
      "                                                                  'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 3, 3, 1024)   0           ['conv4_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 3, 3, 256)    262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 3, 3, 256)    590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 3, 3, 1024)   263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 3, 3, 1024)   0           ['conv4_block2_out[0][0]',       \n",
      "                                                                  'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 3, 3, 1024)   0           ['conv4_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 3, 3, 256)    262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 3, 3, 256)    590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 3, 3, 1024)   263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 3, 3, 1024)   0           ['conv4_block3_out[0][0]',       \n",
      "                                                                  'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 3, 3, 1024)   0           ['conv4_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 3, 3, 256)    262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 3, 3, 256)    590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 3, 3, 1024)   263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 3, 3, 1024)   0           ['conv4_block4_out[0][0]',       \n",
      "                                                                  'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 3, 3, 1024)   0           ['conv4_block5_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 3, 3, 256)    262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 3, 3, 256)    590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 3, 3, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 3, 3, 1024)   0           ['conv4_block5_out[0][0]',       \n",
      "                                                                  'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 3, 3, 1024)   0           ['conv4_block6_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 2, 2, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 2, 2, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 2, 2, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 2, 2, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 2, 2, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 2, 2, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 2, 2, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 2, 2, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 2, 2, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 2, 2, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 2, 2, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 2, 2, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 2, 2, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 2, 2, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 2, 2, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 2, 2, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 512)          1049088     ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 512)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 7)            3591        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 24,640,391\n",
      "Trainable params: 1,052,679\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "87/87 [==============================] - 53s 528ms/step - loss: 2.7554 - accuracy: 0.2406 - val_loss: 1.7935 - val_accuracy: 0.2981\n",
      "Epoch 2/10\n",
      "87/87 [==============================] - 46s 532ms/step - loss: 1.7794 - accuracy: 0.3089 - val_loss: 1.7883 - val_accuracy: 0.3329\n",
      "Epoch 3/10\n",
      "87/87 [==============================] - 48s 545ms/step - loss: 1.7008 - accuracy: 0.3376 - val_loss: 1.7573 - val_accuracy: 0.3256\n",
      "Epoch 4/10\n",
      "87/87 [==============================] - 47s 545ms/step - loss: 1.6254 - accuracy: 0.3722 - val_loss: 1.7492 - val_accuracy: 0.3430\n",
      "Epoch 5/10\n",
      "87/87 [==============================] - 46s 529ms/step - loss: 1.6068 - accuracy: 0.3866 - val_loss: 1.7351 - val_accuracy: 0.3676\n",
      "Epoch 6/10\n",
      "87/87 [==============================] - 58s 665ms/step - loss: 1.5533 - accuracy: 0.3959 - val_loss: 1.7253 - val_accuracy: 0.3661\n",
      "Epoch 7/10\n",
      "87/87 [==============================] - 47s 546ms/step - loss: 1.5341 - accuracy: 0.4081 - val_loss: 1.6988 - val_accuracy: 0.3690\n",
      "Epoch 8/10\n",
      "87/87 [==============================] - 47s 539ms/step - loss: 1.4971 - accuracy: 0.4329 - val_loss: 1.7122 - val_accuracy: 0.3806\n",
      "Epoch 9/10\n",
      "87/87 [==============================] - 47s 544ms/step - loss: 1.4755 - accuracy: 0.4376 - val_loss: 1.7366 - val_accuracy: 0.3835\n",
      "Epoch 10/10\n",
      "87/87 [==============================] - 49s 565ms/step - loss: 1.4528 - accuracy: 0.4538 - val_loss: 1.6961 - val_accuracy: 0.3719\n",
      "Found 802 images belonging to 7 classes.\n",
      "26/26 [==============================] - 11s 435ms/step - loss: 1.5988 - accuracy: 0.3741\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "\n",
    "# Define constants\n",
    "num_classes = 7\n",
    "img_height, img_width = 48, 48\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "# Defining the directories for the training and test data\n",
    "train_dir = '/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/FER-2013/train'\n",
    "test_dir = '/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/FER-2013/test'\n",
    "\n",
    "# Load FER2013 dataset\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    validation_split=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation')\n",
    "\n",
    "# Load pre-trained ResNet50 model\n",
    "base_model = ResNet50(include_top=False, weights='imagenet',\n",
    "                      input_shape=(img_height, img_width, 3))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add new layers for classification\n",
    "x = base_model.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "predictions = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Combine base model and new layers\n",
    "model = keras.Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# define the ModelCheckpoint callback to save the model weights after each epoch\n",
    "checkpoint_callback = ModelCheckpoint('fer2013_model_weights_res_1.1.h5', save_weights_only=True, save_best_only=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    callbacks=[checkpoint_callback]\n",
    "    )\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=1)\n",
    "\n",
    "# Save the model\n",
    "model.save('/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/Models/fer2013_model_res_1.1.h5')\n",
    "model.save_weights('/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/Models/fer2013_model_weights_res_1.1.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GozJQkmPEkU6",
    "outputId": "621f7820-a2fe-4844-cb38-1d5af88f6f33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2781 images belonging to 7 classes.\n",
      "Found 691 images belonging to 7 classes.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 48, 48, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 54, 54, 3)    0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 24, 24, 64)   9472        ['conv1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 24, 24, 64)   256         ['conv1_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 24, 24, 64)   0           ['conv1_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 26, 26, 64)   0           ['conv1_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 12, 12, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 12, 12, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 12, 12, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 12, 12, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 12, 12, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 12, 12, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 12, 12, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 12, 12, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 12, 12, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 12, 12, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 12, 12, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 12, 12, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 12, 12, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 12, 12, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 12, 12, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 12, 12, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 12, 12, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 12, 12, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 12, 12, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 12, 12, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 12, 12, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 12, 12, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 12, 12, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 12, 12, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 12, 12, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 12, 12, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 12, 12, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 12, 12, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 12, 12, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 12, 12, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 6, 6, 128)    32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 6, 6, 128)    147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 6, 6, 512)    131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 6, 6, 512)    66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 6, 6, 512)    0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 6, 6, 512)    0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 6, 6, 128)    65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 6, 6, 128)    147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 6, 6, 512)    66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 6, 6, 512)    0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 6, 6, 512)    0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 6, 6, 128)    65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 6, 6, 128)    147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 6, 6, 512)    66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 6, 6, 512)    0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 6, 6, 512)    0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 6, 6, 128)    65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 6, 6, 128)    147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 6, 6, 128)   512         ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 6, 6, 128)   0           ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 6, 6, 512)    66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 6, 6, 512)   2048        ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 6, 6, 512)    0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 6, 6, 512)    0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 3, 3, 256)    131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 3, 3, 256)    590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 3, 3, 1024)   525312      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 3, 3, 1024)   263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 3, 3, 1024)   0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                                                  'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 3, 3, 1024)   0           ['conv4_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 3, 3, 256)    262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 3, 3, 256)    590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 3, 3, 1024)   263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 3, 3, 1024)   0           ['conv4_block1_out[0][0]',       \n",
      "                                                                  'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 3, 3, 1024)   0           ['conv4_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 3, 3, 256)    262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 3, 3, 256)    590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 3, 3, 1024)   263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 3, 3, 1024)   0           ['conv4_block2_out[0][0]',       \n",
      "                                                                  'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 3, 3, 1024)   0           ['conv4_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 3, 3, 256)    262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 3, 3, 256)    590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 3, 3, 1024)   263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 3, 3, 1024)   0           ['conv4_block3_out[0][0]',       \n",
      "                                                                  'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 3, 3, 1024)   0           ['conv4_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 3, 3, 256)    262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 3, 3, 256)    590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 3, 3, 1024)   263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 3, 3, 1024)   0           ['conv4_block4_out[0][0]',       \n",
      "                                                                  'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 3, 3, 1024)   0           ['conv4_block5_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 3, 3, 256)    262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 3, 3, 256)    590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 3, 3, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 3, 3, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 3, 3, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 3, 3, 1024)  4096        ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 3, 3, 1024)   0           ['conv4_block5_out[0][0]',       \n",
      "                                                                  'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 3, 3, 1024)   0           ['conv4_block6_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 2, 2, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 2, 2, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 2, 2, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 2, 2, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 2, 2, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 2, 2, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 2, 2, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 2, 2, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 2, 2, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 2, 2, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 2, 2, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 2, 2, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 2, 2, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 2, 2, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 2, 2, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 2, 2, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 512)          1049088     ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 512)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 7)            3591        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 24,640,391\n",
      "Trainable params: 1,052,679\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 41/80\n",
      "87/87 [==============================] - 51s 525ms/step - loss: 0.8690 - accuracy: 0.6609 - val_loss: 2.2073 - val_accuracy: 0.4139\n",
      "Epoch 42/80\n",
      "87/87 [==============================] - 44s 503ms/step - loss: 0.7943 - accuracy: 0.6936 - val_loss: 2.3661 - val_accuracy: 0.3893\n",
      "Epoch 43/80\n",
      "87/87 [==============================] - 46s 531ms/step - loss: 0.7679 - accuracy: 0.6994 - val_loss: 2.4118 - val_accuracy: 0.4168\n",
      "Epoch 44/80\n",
      "87/87 [==============================] - 47s 541ms/step - loss: 0.8088 - accuracy: 0.6954 - val_loss: 2.2542 - val_accuracy: 0.4182\n",
      "Epoch 45/80\n",
      "87/87 [==============================] - 47s 540ms/step - loss: 0.7972 - accuracy: 0.6962 - val_loss: 2.1931 - val_accuracy: 0.4298\n",
      "Epoch 46/80\n",
      "87/87 [==============================] - 48s 549ms/step - loss: 0.7553 - accuracy: 0.7113 - val_loss: 2.5376 - val_accuracy: 0.4081\n",
      "Epoch 47/80\n",
      "87/87 [==============================] - 46s 528ms/step - loss: 0.7421 - accuracy: 0.7170 - val_loss: 2.4798 - val_accuracy: 0.4124\n",
      "Epoch 48/80\n",
      "87/87 [==============================] - 47s 541ms/step - loss: 0.7497 - accuracy: 0.7199 - val_loss: 2.3961 - val_accuracy: 0.4038\n",
      "Epoch 49/80\n",
      "87/87 [==============================] - 47s 534ms/step - loss: 0.7085 - accuracy: 0.7343 - val_loss: 2.2965 - val_accuracy: 0.4197\n",
      "Epoch 50/80\n",
      "87/87 [==============================] - 47s 541ms/step - loss: 0.7157 - accuracy: 0.7314 - val_loss: 2.3612 - val_accuracy: 0.4081\n",
      "Epoch 51/80\n",
      "87/87 [==============================] - 43s 498ms/step - loss: 0.7314 - accuracy: 0.7249 - val_loss: 2.3104 - val_accuracy: 0.3980\n",
      "Epoch 52/80\n",
      "87/87 [==============================] - 47s 536ms/step - loss: 0.7595 - accuracy: 0.7066 - val_loss: 2.5123 - val_accuracy: 0.3936\n",
      "Epoch 53/80\n",
      "87/87 [==============================] - 45s 518ms/step - loss: 0.7326 - accuracy: 0.7228 - val_loss: 2.4885 - val_accuracy: 0.4168\n",
      "Epoch 54/80\n",
      "87/87 [==============================] - 44s 503ms/step - loss: 0.7331 - accuracy: 0.7289 - val_loss: 2.3668 - val_accuracy: 0.4182\n",
      "Epoch 55/80\n",
      "87/87 [==============================] - 46s 533ms/step - loss: 0.6993 - accuracy: 0.7325 - val_loss: 2.5589 - val_accuracy: 0.4197\n",
      "Epoch 56/80\n",
      "87/87 [==============================] - 46s 535ms/step - loss: 0.7122 - accuracy: 0.7260 - val_loss: 2.3534 - val_accuracy: 0.3980\n",
      "Epoch 57/80\n",
      "87/87 [==============================] - 43s 493ms/step - loss: 0.6776 - accuracy: 0.7343 - val_loss: 2.2974 - val_accuracy: 0.4197\n",
      "Epoch 58/80\n",
      "87/87 [==============================] - 46s 530ms/step - loss: 0.6686 - accuracy: 0.7494 - val_loss: 2.5025 - val_accuracy: 0.4197\n",
      "Epoch 59/80\n",
      "87/87 [==============================] - 46s 526ms/step - loss: 0.6492 - accuracy: 0.7594 - val_loss: 2.5630 - val_accuracy: 0.4139\n",
      "Epoch 60/80\n",
      "87/87 [==============================] - 46s 533ms/step - loss: 0.6445 - accuracy: 0.7602 - val_loss: 2.4934 - val_accuracy: 0.4139\n",
      "Epoch 61/80\n",
      "87/87 [==============================] - 46s 531ms/step - loss: 0.5871 - accuracy: 0.7760 - val_loss: 2.5029 - val_accuracy: 0.4414\n",
      "Epoch 62/80\n",
      "87/87 [==============================] - 46s 531ms/step - loss: 0.6358 - accuracy: 0.7623 - val_loss: 2.4583 - val_accuracy: 0.4139\n",
      "Epoch 63/80\n",
      "87/87 [==============================] - 46s 525ms/step - loss: 0.6324 - accuracy: 0.7695 - val_loss: 2.6612 - val_accuracy: 0.4052\n",
      "Epoch 64/80\n",
      "87/87 [==============================] - 45s 519ms/step - loss: 0.6550 - accuracy: 0.7508 - val_loss: 2.6143 - val_accuracy: 0.4153\n",
      "Epoch 65/80\n",
      "87/87 [==============================] - 46s 531ms/step - loss: 0.6341 - accuracy: 0.7612 - val_loss: 2.6103 - val_accuracy: 0.3980\n",
      "Epoch 66/80\n",
      "87/87 [==============================] - 46s 532ms/step - loss: 0.6204 - accuracy: 0.7648 - val_loss: 2.6367 - val_accuracy: 0.3835\n",
      "Epoch 67/80\n",
      "87/87 [==============================] - 46s 532ms/step - loss: 0.5901 - accuracy: 0.7767 - val_loss: 2.8037 - val_accuracy: 0.3907\n",
      "Epoch 68/80\n",
      "87/87 [==============================] - 43s 496ms/step - loss: 0.5940 - accuracy: 0.7591 - val_loss: 2.8045 - val_accuracy: 0.3951\n",
      "Epoch 69/80\n",
      "87/87 [==============================] - 46s 532ms/step - loss: 0.5956 - accuracy: 0.7717 - val_loss: 2.7568 - val_accuracy: 0.4182\n",
      "Epoch 70/80\n",
      "87/87 [==============================] - 46s 530ms/step - loss: 0.5564 - accuracy: 0.7857 - val_loss: 2.7210 - val_accuracy: 0.4153\n",
      "Epoch 71/80\n",
      "87/87 [==============================] - 43s 494ms/step - loss: 0.5537 - accuracy: 0.7814 - val_loss: 2.8566 - val_accuracy: 0.3907\n",
      "Epoch 72/80\n",
      "87/87 [==============================] - 46s 534ms/step - loss: 0.5275 - accuracy: 0.7968 - val_loss: 2.8999 - val_accuracy: 0.4139\n",
      "Epoch 73/80\n",
      "87/87 [==============================] - 46s 532ms/step - loss: 0.5438 - accuracy: 0.7860 - val_loss: 2.8810 - val_accuracy: 0.4023\n",
      "Epoch 74/80\n",
      "87/87 [==============================] - 46s 533ms/step - loss: 0.5480 - accuracy: 0.7914 - val_loss: 2.8554 - val_accuracy: 0.4023\n",
      "Epoch 75/80\n",
      "87/87 [==============================] - 46s 533ms/step - loss: 0.5532 - accuracy: 0.7832 - val_loss: 2.7748 - val_accuracy: 0.4226\n",
      "Epoch 76/80\n",
      "87/87 [==============================] - 46s 534ms/step - loss: 0.5512 - accuracy: 0.7839 - val_loss: 2.8423 - val_accuracy: 0.4153\n",
      "Epoch 77/80\n",
      "87/87 [==============================] - 57s 650ms/step - loss: 0.5167 - accuracy: 0.7983 - val_loss: 2.9771 - val_accuracy: 0.4023\n",
      "Epoch 78/80\n",
      "87/87 [==============================] - 46s 530ms/step - loss: 0.5702 - accuracy: 0.7875 - val_loss: 2.8188 - val_accuracy: 0.4038\n",
      "Epoch 79/80\n",
      "87/87 [==============================] - 43s 493ms/step - loss: 0.5720 - accuracy: 0.7825 - val_loss: 2.9084 - val_accuracy: 0.4023\n",
      "Epoch 80/80\n",
      "87/87 [==============================] - 46s 525ms/step - loss: 0.5647 - accuracy: 0.7860 - val_loss: 2.9918 - val_accuracy: 0.4023\n",
      "Found 802 images belonging to 7 classes.\n",
      "26/26 [==============================] - 11s 440ms/step - loss: 2.8283 - accuracy: 0.3903\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "\n",
    "# Define constants\n",
    "num_classes = 7\n",
    "img_height, img_width = 48, 48\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "# Defining the directories for the training and test data\n",
    "train_dir = '/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/FER-2013/train'\n",
    "test_dir = '/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/FER-2013/test'\n",
    "\n",
    "# Load FER2013 dataset\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    validation_split=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation')\n",
    "\n",
    "# Creating an instance of the trained model\n",
    "model = load_model('/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/Models/fer2013_model_res_1.2.h5')\n",
    "\n",
    "# Load the weights for your model\n",
    "model.load_weights('/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/Models/fer2013_model_weights_res_1.2.h5')\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# define the ModelCheckpoint callback to save the model weights after each epoch\n",
    "checkpoint_callback = ModelCheckpoint('fer2013_model_weights_res_1.3.h5', save_weights_only=True, save_best_only=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=80,\n",
    "    initial_epoch=40,\n",
    "    verbose=1,\n",
    "    callbacks=[checkpoint_callback]\n",
    "    )\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=1)\n",
    "\n",
    "# Save the model\n",
    "model.save('/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/Models/fer2013_model_res_1.3.h5')\n",
    "model.save_weights('/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/Models/fer2013_model_weights_res_1.3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jggomCVKEkJs",
    "outputId": "5cafbfd8-830d-47d8-d764-2eb6052cfa60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 11s 427ms/step - loss: 2.8283 - accuracy: 0.3903\n",
      "2.8283021450042725   0.390274316072464\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_generator, verbose=1)\n",
    "print(test_loss, ' ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lF-2PEh5Lo-9",
    "outputId": "17fdd2b2-5864-4b80-9d7c-8e7231db8a57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_17 (InputLayer)       [(None, 48, 48, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 48, 48, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 48, 48, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 24, 24, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 12, 12, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 6, 6, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 6, 6, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten_18 (Flatten)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,879,815\n",
      "Trainable params: 165,127\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n",
      "Found 3472 images belonging to 7 classes.\n",
      "Found 802 images belonging to 7 classes.\n",
      "Epoch 1/50\n",
      "54/54 [==============================] - 117s 2s/step - loss: 1.9198 - accuracy: 0.2107 - val_loss: 1.8178 - val_accuracy: 0.2591\n",
      "Epoch 2/50\n",
      "54/54 [==============================] - 115s 2s/step - loss: 1.8207 - accuracy: 0.2708 - val_loss: 1.8075 - val_accuracy: 0.2773\n",
      "Epoch 3/50\n",
      "54/54 [==============================] - 117s 2s/step - loss: 1.7823 - accuracy: 0.2940 - val_loss: 1.7337 - val_accuracy: 0.3542\n",
      "Epoch 4/50\n",
      "54/54 [==============================] - 115s 2s/step - loss: 1.7626 - accuracy: 0.3011 - val_loss: 1.8043 - val_accuracy: 0.2904\n",
      "Epoch 5/50\n",
      "54/54 [==============================] - 115s 2s/step - loss: 1.7346 - accuracy: 0.3148 - val_loss: 1.8149 - val_accuracy: 0.2956\n",
      "Epoch 6/50\n",
      "54/54 [==============================] - 115s 2s/step - loss: 1.7223 - accuracy: 0.3245 - val_loss: 1.7308 - val_accuracy: 0.3242\n",
      "Epoch 7/50\n",
      "54/54 [==============================] - 114s 2s/step - loss: 1.6999 - accuracy: 0.3421 - val_loss: 1.7406 - val_accuracy: 0.3281\n",
      "Epoch 8/50\n",
      "54/54 [==============================] - 113s 2s/step - loss: 1.6983 - accuracy: 0.3504 - val_loss: 1.7532 - val_accuracy: 0.3294\n",
      "Epoch 9/50\n",
      "54/54 [==============================] - 112s 2s/step - loss: 1.6817 - accuracy: 0.3348 - val_loss: 1.8017 - val_accuracy: 0.3008\n",
      "Epoch 10/50\n",
      "54/54 [==============================] - 113s 2s/step - loss: 1.6583 - accuracy: 0.3580 - val_loss: 1.7649 - val_accuracy: 0.3060\n",
      "Epoch 11/50\n",
      "54/54 [==============================] - 114s 2s/step - loss: 1.6625 - accuracy: 0.3615 - val_loss: 1.7351 - val_accuracy: 0.3385\n",
      "Epoch 12/50\n",
      "54/54 [==============================] - 113s 2s/step - loss: 1.6429 - accuracy: 0.3492 - val_loss: 1.7299 - val_accuracy: 0.3268\n",
      "Epoch 13/50\n",
      "54/54 [==============================] - 113s 2s/step - loss: 1.6306 - accuracy: 0.3744 - val_loss: 1.7658 - val_accuracy: 0.3099\n",
      "Epoch 14/50\n",
      "54/54 [==============================] - 113s 2s/step - loss: 1.6118 - accuracy: 0.3906 - val_loss: 1.7323 - val_accuracy: 0.3268\n",
      "Epoch 15/50\n",
      "54/54 [==============================] - 114s 2s/step - loss: 1.6233 - accuracy: 0.3759 - val_loss: 1.7473 - val_accuracy: 0.3490\n",
      "Epoch 16/50\n",
      "54/54 [==============================] - 113s 2s/step - loss: 1.6056 - accuracy: 0.3882 - val_loss: 1.7257 - val_accuracy: 0.3294\n",
      "Epoch 17/50\n",
      "54/54 [==============================] - 114s 2s/step - loss: 1.5883 - accuracy: 0.3888 - val_loss: 1.7408 - val_accuracy: 0.3372\n",
      "Epoch 18/50\n",
      "54/54 [==============================] - 135s 3s/step - loss: 1.5809 - accuracy: 0.3958 - val_loss: 1.6774 - val_accuracy: 0.3594\n",
      "Epoch 19/50\n",
      "54/54 [==============================] - 120s 2s/step - loss: 1.5863 - accuracy: 0.3914 - val_loss: 1.7271 - val_accuracy: 0.3411\n",
      "Epoch 20/50\n",
      "54/54 [==============================] - 114s 2s/step - loss: 1.5713 - accuracy: 0.3955 - val_loss: 1.7095 - val_accuracy: 0.3477\n",
      "Epoch 21/50\n",
      "54/54 [==============================] - 134s 2s/step - loss: 1.5673 - accuracy: 0.4070 - val_loss: 1.7812 - val_accuracy: 0.3372\n",
      "Epoch 22/50\n",
      "54/54 [==============================] - 113s 2s/step - loss: 1.5476 - accuracy: 0.4038 - val_loss: 1.7582 - val_accuracy: 0.3333\n",
      "Epoch 23/50\n",
      "54/54 [==============================] - 112s 2s/step - loss: 1.5478 - accuracy: 0.4026 - val_loss: 1.7669 - val_accuracy: 0.3411\n",
      "Epoch 24/50\n",
      "54/54 [==============================] - 114s 2s/step - loss: 1.5362 - accuracy: 0.4173 - val_loss: 1.7196 - val_accuracy: 0.3555\n",
      "Epoch 25/50\n",
      "54/54 [==============================] - 134s 2s/step - loss: 1.5426 - accuracy: 0.4175 - val_loss: 1.7031 - val_accuracy: 0.3568\n",
      "Epoch 26/50\n",
      "54/54 [==============================] - 112s 2s/step - loss: 1.5028 - accuracy: 0.4217 - val_loss: 1.7786 - val_accuracy: 0.3451\n",
      "Epoch 27/50\n",
      "54/54 [==============================] - 113s 2s/step - loss: 1.5252 - accuracy: 0.4120 - val_loss: 1.8260 - val_accuracy: 0.3346\n",
      "Epoch 28/50\n",
      "54/54 [==============================] - 133s 2s/step - loss: 1.5286 - accuracy: 0.4187 - val_loss: 1.7443 - val_accuracy: 0.3529\n",
      "Epoch 29/50\n",
      "54/54 [==============================] - 113s 2s/step - loss: 1.4935 - accuracy: 0.4369 - val_loss: 1.7182 - val_accuracy: 0.3464\n",
      "Epoch 30/50\n",
      "54/54 [==============================] - 113s 2s/step - loss: 1.5000 - accuracy: 0.4363 - val_loss: 1.7185 - val_accuracy: 0.3477\n",
      "Epoch 31/50\n",
      "54/54 [==============================] - 125s 2s/step - loss: 1.4808 - accuracy: 0.4422 - val_loss: 1.7433 - val_accuracy: 0.3568\n",
      "Epoch 32/50\n",
      "54/54 [==============================] - 115s 2s/step - loss: 1.4613 - accuracy: 0.4492 - val_loss: 1.7480 - val_accuracy: 0.3385\n",
      "Epoch 33/50\n",
      "54/54 [==============================] - 115s 2s/step - loss: 1.4750 - accuracy: 0.4472 - val_loss: 1.7971 - val_accuracy: 0.3372\n",
      "Epoch 34/50\n",
      "54/54 [==============================] - 114s 2s/step - loss: 1.4838 - accuracy: 0.4346 - val_loss: 1.7572 - val_accuracy: 0.3620\n",
      "Epoch 35/50\n",
      "54/54 [==============================] - 135s 3s/step - loss: 1.4644 - accuracy: 0.4457 - val_loss: 1.7725 - val_accuracy: 0.3529\n",
      "Epoch 36/50\n",
      "54/54 [==============================] - 114s 2s/step - loss: 1.4355 - accuracy: 0.4572 - val_loss: 1.7885 - val_accuracy: 0.3633\n",
      "Epoch 37/50\n",
      "54/54 [==============================] - 135s 2s/step - loss: 1.4484 - accuracy: 0.4457 - val_loss: 1.8025 - val_accuracy: 0.3411\n",
      "Epoch 38/50\n",
      "54/54 [==============================] - 116s 2s/step - loss: 1.4324 - accuracy: 0.4522 - val_loss: 1.7550 - val_accuracy: 0.3724\n",
      "Epoch 39/50\n",
      "54/54 [==============================] - 115s 2s/step - loss: 1.4147 - accuracy: 0.4621 - val_loss: 1.7928 - val_accuracy: 0.3594\n",
      "Epoch 40/50\n",
      "54/54 [==============================] - 117s 2s/step - loss: 1.4446 - accuracy: 0.4519 - val_loss: 1.7797 - val_accuracy: 0.3516\n",
      "Epoch 41/50\n",
      "54/54 [==============================] - 117s 2s/step - loss: 1.4205 - accuracy: 0.4586 - val_loss: 1.7877 - val_accuracy: 0.3307\n",
      "Epoch 42/50\n",
      "54/54 [==============================] - 123s 2s/step - loss: 1.4102 - accuracy: 0.4707 - val_loss: 1.8297 - val_accuracy: 0.3477\n",
      "Epoch 43/50\n",
      "54/54 [==============================] - 148s 3s/step - loss: 1.4173 - accuracy: 0.4680 - val_loss: 1.8308 - val_accuracy: 0.3333\n",
      "Epoch 44/50\n",
      "54/54 [==============================] - 135s 2s/step - loss: 1.3979 - accuracy: 0.4856 - val_loss: 1.9001 - val_accuracy: 0.3503\n",
      "Epoch 45/50\n",
      "54/54 [==============================] - 114s 2s/step - loss: 1.4138 - accuracy: 0.4718 - val_loss: 1.8635 - val_accuracy: 0.3333\n",
      "Epoch 46/50\n",
      "54/54 [==============================] - 116s 2s/step - loss: 1.4029 - accuracy: 0.4580 - val_loss: 1.8348 - val_accuracy: 0.3294\n",
      "Epoch 47/50\n",
      "54/54 [==============================] - 117s 2s/step - loss: 1.3834 - accuracy: 0.4739 - val_loss: 1.9757 - val_accuracy: 0.3542\n",
      "Epoch 48/50\n",
      "54/54 [==============================] - 115s 2s/step - loss: 1.3752 - accuracy: 0.4982 - val_loss: 1.9211 - val_accuracy: 0.3346\n",
      "Epoch 49/50\n",
      "54/54 [==============================] - 114s 2s/step - loss: 1.3881 - accuracy: 0.4777 - val_loss: 1.8013 - val_accuracy: 0.3620\n",
      "Epoch 50/50\n",
      "54/54 [==============================] - 135s 3s/step - loss: 1.3694 - accuracy: 0.4850 - val_loss: 1.8515 - val_accuracy: 0.3424\n",
      "Test accuracy: 0.3503740727901459\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "# Load the pre-trained VGG16 model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
    "\n",
    "# Freeze the pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add new trainable layers\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "predictions = Dense(7, activation='softmax')(x)\n",
    "\n",
    "# Create the new model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# Defining the emotion labels\n",
    "emotion_labels = {\n",
    "    0: 'Angry',\n",
    "    1: 'Disgust',\n",
    "    2: 'Fear',\n",
    "    3: 'Happy',\n",
    "    4: 'Sad',\n",
    "    5: 'Surprise',\n",
    "    6: 'Neutral'\n",
    "}\n",
    "\n",
    "# Defining the image dimensions and number of classes\n",
    "img_height = 48\n",
    "img_width = 48\n",
    "num_classes = 7\n",
    "\n",
    "# Defining the directories for the training and test data\n",
    "train_dir = '/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/FER-2013/train'\n",
    "test_dir = '/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/FER-2013/test'\n",
    "\n",
    "# def grayscale_to_rgb(img):\n",
    "#     print(img.shape)\n",
    "#     # Convert grayscale to RGB image\n",
    "#     img_rgb = tf.tile(img, [1, 1, 3, 1])\n",
    "#     img_rgb = tf.squeeze(img_rgb, axis=-1)\n",
    "#     print(img_rgb.shape)\n",
    "#     return img_rgb\n",
    "\n",
    "\n",
    "# Load the training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    # preprocessing_function=grayscale_to_rgb,\n",
    "    rotation_range=30,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    color_mode='rgb',\n",
    "    batch_size=64,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "# Loading the test data\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    # preprocessing_function=grayscale_to_rgb\n",
    ")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    color_mode='rgb',\n",
    "    batch_size=64,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# define the ModelCheckpoint callback to save the model weights after each epoch\n",
    "checkpoint_callback = ModelCheckpoint('fer2013_model_weights_img_net.h5', save_weights_only=True, save_best_only=True)\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.n // train_generator.batch_size,\n",
    "    epochs=50,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.n // test_generator.batch_size,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "\n",
    "\n",
    "# Evaluating the model on the test set\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=0)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# Saving the model\n",
    "model.save('fer2013_model_img_net.h5')\n",
    "model.save_weights('fer2013_model_weights_img_net.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s6XBTlAiGDeL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zuU-p5IVFoUn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sEQqLwi1Fot_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "lHB7XYw_Fowl",
    "outputId": "5c0d1fdf-85d5-4c7a-f3fd-4b68ef39fd65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3472 images belonging to 7 classes.\n",
      "Found 802 images belonging to 7 classes.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-0634baa0d90e>\u001b[0m in \u001b[0;36m<cell line: 63>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m# Defining the model architecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m model = Sequential([\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/trackable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/layers/convolutional/base_conv.py\u001b[0m in \u001b[0;36mcompute_output_shape\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    355\u001b[0m                 \u001b[0;34m\"One of the dimensions in the output is <= 0 \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"due to downsampling in {self.name}. Consider \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: One of the dimensions in the output is <= 0 due to downsampling in conv2d_55. Consider increasing the input size. Received input shape [None, 1, 1, 256] which would produce output shape with a zero or negative value in a dimension."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Defining the emotion labels\n",
    "emotion_labels = {\n",
    "    0: 'Angry',\n",
    "    1: 'Disgust',\n",
    "    2: 'Fear',\n",
    "    3: 'Happy',\n",
    "    4: 'Sad',\n",
    "    5: 'Surprise',\n",
    "    6: 'Neutral'\n",
    "}\n",
    "\n",
    "# Defining the image dimensions and number of classes\n",
    "img_height = 48\n",
    "img_width = 48\n",
    "num_classes = 7\n",
    "\n",
    "# Defining the directories for the training and test data\n",
    "train_dir = '/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/FER-2013/train'\n",
    "test_dir = '/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/FER-2013/test'\n",
    "\n",
    "# Loading the training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=64,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "# Loading the test data\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=64,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "# Defining the model architecture\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(256, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "# # Creating an instance of the trained model\n",
    "# model = load_model('/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/Models/fer2013_model_i.2.h5')\n",
    "\n",
    "# # Load the weights for your model\n",
    "# model.load_weights('/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/Models/fer2013_model_weights_i.2.h5')\n",
    "\n",
    "# Compile the model with categorical cross-entropy loss, adam optimizer, and accuracy metric\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer= tf.keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# define the ModelCheckpoint callback to save the model weights after each epoch\n",
    "checkpoint_callback = ModelCheckpoint('fer2013_model_weights_i.1.h5', save_weights_only=True, save_best_only=True)\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.n // train_generator.batch_size,\n",
    "    epochs=50,\n",
    "    # initial_epoch=80,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.n // test_generator.batch_size,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "\n",
    "# Evaluating the model on the test set\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=0)\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Test loss:', test_loss)\n",
    "\n",
    "# Saving the model\n",
    "model.save('/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/Models/fer2013_model_i.1.h5')\n",
    "model.save_weights('/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/Models/fer2013_model_weights_i.1.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sPAEQXSZo5Zs",
    "outputId": "952b3d1f-1bf3-4209-dc17-f54583197dbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3472 images belonging to 7 classes.\n",
      "Found 802 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Defining the emotion labels\n",
    "emotion_labels = {\n",
    "    0: 'Angry',\n",
    "    1: 'Disgust',\n",
    "    2: 'Fear',\n",
    "    3: 'Happy',\n",
    "    4: 'Sad',\n",
    "    5: 'Surprise',\n",
    "    6: 'Neutral'\n",
    "}\n",
    "\n",
    "# Defining the image dimensions and number of classes\n",
    "img_height = 48\n",
    "img_width = 48\n",
    "num_classes = 7\n",
    "\n",
    "# Defining the directories for the training and test data\n",
    "train_dir = '/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/FER-2013/train'\n",
    "test_dir = '/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/FER-2013/test'\n",
    "\n",
    "# Loading the training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=64,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "# Loading the test data\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=64,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "\n",
    "import hyperopt\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define early stopping criteria\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "def objective(params):\n",
    "    model = Sequential([\n",
    "        Conv2D(params['filters'], (3, 3), activation='relu', input_shape=(img_height, img_width, 1)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(params['filters'] * 2, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(params['filters'] * 2, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(params['filters'] * 2, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dropout(params['dropout']),\n",
    "        Dense(params['dense_units'], activation='relu'),\n",
    "        Dropout(params['dropout']),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(train_generator, validation_data=test_generator, epochs=params['epochs'], callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "    val_acc = max(history.history['val_accuracy'])\n",
    "\n",
    "    return {'loss': -val_acc, 'status': STATUS_OK, 'model': model}\n",
    "\n",
    "\n",
    "space = {\n",
    "    'filters': hp.choice('filters', [32, 64, 128]),\n",
    "    'dense_units': hp.choice('dense_units', [128, 256, 512]),\n",
    "    'dropout': hp.uniform('dropout', 0.2, 0.5),\n",
    "    'epochs': hp.choice('epochs', [10, 20, 30, 50])\n",
    "}\n",
    "\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50)\n",
    "\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "QQ-ey5nuFoy1",
    "outputId": "b151f623-f5de-4650-ce6a-2b5af04d24f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6%|         | 3/50 [2:00:20<31:25:21, 2406.85s/trial, best loss: -0.42518702149391174]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-5384b4ec59cc>\u001b[0m in \u001b[0;36m<cell line: 45>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m best = fmin(fn=objective,\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;31m# next line is where the fmin is actually executed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                     \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"job exception: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    890\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             )\n\u001b[0;32m--> 892\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-5384b4ec59cc>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import hyperopt\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define early stopping criteria\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "def objective(params):\n",
    "    model = Sequential([\n",
    "        Conv2D(params['filters'], (3, 3), activation='relu', input_shape=(img_height, img_width, 1)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(params['filters'] * 2, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(params['filters'] * 2, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(params['filters'] * 2, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dropout(params['dropout']),\n",
    "        Dense(params['dense_units'], activation='relu'),\n",
    "        Dropout(params['dropout']),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(train_generator, validation_data=test_generator, epochs=params['epochs'], callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "    val_acc = max(history.history['val_accuracy'])\n",
    "\n",
    "    return {'loss': -val_acc, 'status': STATUS_OK, 'model': model}\n",
    "\n",
    "\n",
    "space = {\n",
    "    'filters': hp.choice('filters', [32, 64, 128]),\n",
    "    'dense_units': hp.choice('dense_units', [128, 256, 512]),\n",
    "    'dropout': hp.uniform('dropout', 0.2, 0.5),\n",
    "    'epochs': hp.choice('epochs', [10, 20, 30, 50])\n",
    "}\n",
    "\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50)\n",
    "\n",
    "\n",
    "print(best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LsuOK0qEJIsE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t-qXMXaEXnLl"
   },
   "outputs": [],
   "source": [
    "# Normalizing the dataset\n",
    "'''\n",
    "The fer2013new dataset contains the emotion values ranging from - to 10.\n",
    "Instead, we normalize it to range between 0-1;\n",
    "\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def clean_data_and_normalize(filename, output_filename):\n",
    "    # Read data into DataFrame\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    # Remove any rows with missing or invalid data\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # Separate image names from rest of data\n",
    "    image_names = df['Image name']\n",
    "    df = df.drop('Image name', axis=1)\n",
    "\n",
    "    # Separate Usage from rest of data\n",
    "    Usage = df['Usage']\n",
    "    df = df.drop('Usage', axis=1)\n",
    "\n",
    "    # Convert emotion scores to floats\n",
    "    df = df.astype(float)\n",
    "\n",
    "    # Normalize emotion scores for each image\n",
    "    df = df.div(df.sum(axis=1), axis=0)\n",
    "\n",
    "    # Add image names back to DataFrame\n",
    "    df.insert(0, 'Usage', Usage)\n",
    "\n",
    "    # Add image names back to DataFrame\n",
    "    df.insert(1, 'Image name', image_names)\n",
    "\n",
    "    # Save cleaned and normalized data to new CSV file\n",
    "    df.to_csv(output_filename, index=False)\n",
    "\n",
    "clean_data_and_normalize('/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/fer2013new/fer2013new.csv', 'fer2013new1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iUskJGpnTBwv",
    "outputId": "84ee1679-fc25-4b05-f8af-06499d659be5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28501 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py:1137: UserWarning: Found 60 invalid image filename(s) in x_col=\"Image name\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3579 validated image filenames.\n",
      "Found 3574 validated image filenames.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_10 (Conv2D)          (None, 46, 46, 64)        640       \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 46, 46, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 46, 46, 64)        0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 44, 44, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 44, 44, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 44, 44, 64)        0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 44, 44, 64)        0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 42, 42, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 40, 40, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 20, 20, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 18, 18, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 18, 18, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 18, 18, 128)       0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 16, 16, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 14, 14, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 12, 12, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 6, 6, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 4, 4, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 4, 4, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 2, 2, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 2, 2, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 2, 2, 256)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 7)                 7175      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,623,239\n",
      "Trainable params: 3,621,447\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "445/445 [==============================] - 6410s 14s/step - loss: 0.3566 - accuracy: 0.3329 - val_loss: 0.3784 - val_accuracy: 0.3810\n",
      "Epoch 2/50\n",
      "445/445 [==============================] - 68s 152ms/step - loss: 0.3484 - accuracy: 0.3527 - val_loss: 0.3522 - val_accuracy: 0.3818\n",
      "Epoch 3/50\n",
      "445/445 [==============================] - 69s 155ms/step - loss: 0.3468 - accuracy: 0.3537 - val_loss: 0.3501 - val_accuracy: 0.3801\n",
      "Epoch 4/50\n",
      "445/445 [==============================] - 67s 151ms/step - loss: 0.3449 - accuracy: 0.3645 - val_loss: 0.3504 - val_accuracy: 0.3844\n",
      "Epoch 5/50\n",
      "445/445 [==============================] - 74s 165ms/step - loss: 0.3431 - accuracy: 0.3766 - val_loss: 0.3544 - val_accuracy: 0.3795\n",
      "Epoch 6/50\n",
      "445/445 [==============================] - 68s 153ms/step - loss: 0.3406 - accuracy: 0.3914 - val_loss: 0.3309 - val_accuracy: 0.4307\n",
      "Epoch 7/50\n",
      "445/445 [==============================] - 68s 152ms/step - loss: 0.3369 - accuracy: 0.4129 - val_loss: 0.3162 - val_accuracy: 0.4875\n",
      "Epoch 8/50\n",
      "445/445 [==============================] - 68s 152ms/step - loss: 0.3303 - accuracy: 0.4409 - val_loss: 0.2915 - val_accuracy: 0.5608\n",
      "Epoch 9/50\n",
      "445/445 [==============================] - 67s 150ms/step - loss: 0.3232 - accuracy: 0.4651 - val_loss: 0.2901 - val_accuracy: 0.5696\n",
      "Epoch 10/50\n",
      "445/445 [==============================] - 68s 152ms/step - loss: 0.3166 - accuracy: 0.4871 - val_loss: 0.2700 - val_accuracy: 0.6074\n",
      "Epoch 11/50\n",
      "445/445 [==============================] - 66s 149ms/step - loss: 0.3102 - accuracy: 0.5076 - val_loss: 0.2627 - val_accuracy: 0.6352\n",
      "Epoch 12/50\n",
      "445/445 [==============================] - 67s 150ms/step - loss: 0.3041 - accuracy: 0.5275 - val_loss: 0.2613 - val_accuracy: 0.6517\n",
      "Epoch 13/50\n",
      "445/445 [==============================] - 68s 152ms/step - loss: 0.2998 - accuracy: 0.5384 - val_loss: 0.2490 - val_accuracy: 0.6642\n",
      "Epoch 14/50\n",
      "445/445 [==============================] - 67s 150ms/step - loss: 0.2947 - accuracy: 0.5534 - val_loss: 0.2495 - val_accuracy: 0.6668\n",
      "Epoch 15/50\n",
      "445/445 [==============================] - 67s 150ms/step - loss: 0.2915 - accuracy: 0.5613 - val_loss: 0.2405 - val_accuracy: 0.6869\n",
      "Epoch 16/50\n",
      "445/445 [==============================] - 65s 147ms/step - loss: 0.2880 - accuracy: 0.5702 - val_loss: 0.2416 - val_accuracy: 0.6648\n",
      "Epoch 17/50\n",
      "445/445 [==============================] - 66s 148ms/step - loss: 0.2846 - accuracy: 0.5767 - val_loss: 0.2334 - val_accuracy: 0.6918\n",
      "Epoch 18/50\n",
      "445/445 [==============================] - 67s 151ms/step - loss: 0.2816 - accuracy: 0.5860 - val_loss: 0.2292 - val_accuracy: 0.7139\n",
      "Epoch 19/50\n",
      "445/445 [==============================] - 66s 149ms/step - loss: 0.2803 - accuracy: 0.5889 - val_loss: 0.2321 - val_accuracy: 0.7071\n",
      "Epoch 20/50\n",
      "445/445 [==============================] - 67s 150ms/step - loss: 0.2771 - accuracy: 0.5991 - val_loss: 0.2320 - val_accuracy: 0.6716\n",
      "Epoch 21/50\n",
      "445/445 [==============================] - 68s 152ms/step - loss: 0.2756 - accuracy: 0.5982 - val_loss: 0.2241 - val_accuracy: 0.7111\n",
      "Epoch 22/50\n",
      "445/445 [==============================] - 71s 160ms/step - loss: 0.2729 - accuracy: 0.6096 - val_loss: 0.2205 - val_accuracy: 0.7168\n",
      "Epoch 23/50\n",
      "445/445 [==============================] - 67s 151ms/step - loss: 0.2717 - accuracy: 0.6124 - val_loss: 0.2240 - val_accuracy: 0.7230\n",
      "Epoch 24/50\n",
      "445/445 [==============================] - 71s 160ms/step - loss: 0.2697 - accuracy: 0.6181 - val_loss: 0.2347 - val_accuracy: 0.6886\n",
      "Epoch 25/50\n",
      "445/445 [==============================] - 72s 161ms/step - loss: 0.2685 - accuracy: 0.6183 - val_loss: 0.2349 - val_accuracy: 0.7045\n",
      "Epoch 26/50\n",
      "445/445 [==============================] - 66s 148ms/step - loss: 0.2661 - accuracy: 0.6221 - val_loss: 0.2166 - val_accuracy: 0.7284\n",
      "Epoch 27/50\n",
      "445/445 [==============================] - 72s 161ms/step - loss: 0.2657 - accuracy: 0.6282 - val_loss: 0.2295 - val_accuracy: 0.7017\n",
      "Epoch 28/50\n",
      "445/445 [==============================] - 67s 151ms/step - loss: 0.2642 - accuracy: 0.6303 - val_loss: 0.2140 - val_accuracy: 0.7423\n",
      "Epoch 29/50\n",
      "445/445 [==============================] - 71s 160ms/step - loss: 0.2626 - accuracy: 0.6345 - val_loss: 0.2128 - val_accuracy: 0.7497\n",
      "Epoch 30/50\n",
      "445/445 [==============================] - 67s 150ms/step - loss: 0.2615 - accuracy: 0.6357 - val_loss: 0.2205 - val_accuracy: 0.7196\n",
      "Epoch 31/50\n",
      "445/445 [==============================] - 66s 148ms/step - loss: 0.2607 - accuracy: 0.6409 - val_loss: 0.2145 - val_accuracy: 0.7384\n",
      "Epoch 32/50\n",
      "445/445 [==============================] - 65s 147ms/step - loss: 0.2601 - accuracy: 0.6423 - val_loss: 0.2132 - val_accuracy: 0.7437\n",
      "Epoch 33/50\n",
      "445/445 [==============================] - 66s 149ms/step - loss: 0.2578 - accuracy: 0.6456 - val_loss: 0.2135 - val_accuracy: 0.7520\n",
      "Epoch 34/50\n",
      "445/445 [==============================] - 66s 147ms/step - loss: 0.2573 - accuracy: 0.6458 - val_loss: 0.2081 - val_accuracy: 0.7443\n",
      "Epoch 35/50\n",
      "445/445 [==============================] - 68s 152ms/step - loss: 0.2562 - accuracy: 0.6505 - val_loss: 0.2118 - val_accuracy: 0.7332\n",
      "Epoch 36/50\n",
      "445/445 [==============================] - 66s 148ms/step - loss: 0.2547 - accuracy: 0.6521 - val_loss: 0.2245 - val_accuracy: 0.7071\n",
      "Epoch 37/50\n",
      "445/445 [==============================] - 66s 148ms/step - loss: 0.2542 - accuracy: 0.6547 - val_loss: 0.2115 - val_accuracy: 0.7389\n",
      "Epoch 38/50\n",
      "445/445 [==============================] - 68s 153ms/step - loss: 0.2531 - accuracy: 0.6582 - val_loss: 0.2028 - val_accuracy: 0.7585\n",
      "Epoch 39/50\n",
      "445/445 [==============================] - 66s 149ms/step - loss: 0.2523 - accuracy: 0.6603 - val_loss: 0.2095 - val_accuracy: 0.7474\n",
      "Epoch 40/50\n",
      "445/445 [==============================] - 67s 150ms/step - loss: 0.2516 - accuracy: 0.6603 - val_loss: 0.2048 - val_accuracy: 0.7628\n",
      "Epoch 41/50\n",
      "445/445 [==============================] - 66s 147ms/step - loss: 0.2513 - accuracy: 0.6634 - val_loss: 0.2015 - val_accuracy: 0.7605\n",
      "Epoch 42/50\n",
      "445/445 [==============================] - 66s 147ms/step - loss: 0.2502 - accuracy: 0.6675 - val_loss: 0.1985 - val_accuracy: 0.7685\n",
      "Epoch 43/50\n",
      "445/445 [==============================] - 72s 162ms/step - loss: 0.2493 - accuracy: 0.6730 - val_loss: 0.2079 - val_accuracy: 0.7528\n",
      "Epoch 44/50\n",
      "445/445 [==============================] - 66s 148ms/step - loss: 0.2497 - accuracy: 0.6691 - val_loss: 0.2036 - val_accuracy: 0.7665\n",
      "Epoch 45/50\n",
      "445/445 [==============================] - 65s 147ms/step - loss: 0.2482 - accuracy: 0.6715 - val_loss: 0.2043 - val_accuracy: 0.7619\n",
      "Epoch 46/50\n",
      "445/445 [==============================] - 67s 150ms/step - loss: 0.2491 - accuracy: 0.6694 - val_loss: 0.2113 - val_accuracy: 0.7312\n",
      "Epoch 47/50\n",
      "445/445 [==============================] - 66s 147ms/step - loss: 0.2471 - accuracy: 0.6762 - val_loss: 0.2026 - val_accuracy: 0.7682\n",
      "Epoch 48/50\n",
      "445/445 [==============================] - 68s 153ms/step - loss: 0.2470 - accuracy: 0.6744 - val_loss: 0.2124 - val_accuracy: 0.7361\n",
      "Epoch 49/50\n",
      "445/445 [==============================] - 66s 149ms/step - loss: 0.2459 - accuracy: 0.6725 - val_loss: 0.2003 - val_accuracy: 0.7653\n",
      "Epoch 50/50\n",
      "445/445 [==============================] - 71s 159ms/step - loss: 0.2447 - accuracy: 0.6801 - val_loss: 0.2042 - val_accuracy: 0.7591\n",
      "55/55 [==============================] - 713s 13s/step - loss: 0.2091 - accuracy: 0.7449\n",
      "Test accuracy: 0.7448863387107849\n",
      "Test loss: 0.2091161161661148\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Activation\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define the paths to the dataset folders and CSV file\n",
    "train_path = '/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/fer2013new/FER2013Train'\n",
    "valid_path = '/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/fer2013new/FER2013Valid'\n",
    "test_path = '/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/fer2013new/FER2013Test'\n",
    "csv_path = '/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/fer2013new/fer2013new1.csv'\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# # Remove rows with empty 'Image name' values\n",
    "# df.dropna(subset=['Image name'], inplace=True)\n",
    "\n",
    "\n",
    "# Define the parameters for the image data generator\n",
    "img_width = 48\n",
    "img_height = 48\n",
    "batch_size = 64\n",
    "\n",
    "# Create the image data generator for training data with data augmentation\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=30,\n",
    "                                   shear_range=0.3,\n",
    "                                   zoom_range=0.3,\n",
    "                                   width_shift_range=0.4,\n",
    "                                   height_shift_range=0.4,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "# Create the image data generator for validation and test data without data augmentation\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create the generator for loading the training data from the folder\n",
    "train_generator = train_datagen.flow_from_dataframe(dataframe=df[df['Usage']=='Training'],\n",
    "                                                    directory=train_path,\n",
    "                                                    x_col=\"Image name\",\n",
    "                                                    y_col=[\"neutral\", \"happiness\", \"surprise\", \"sadness\", \"anger\", \"disgust\", \"fear\"],\n",
    "                                                    target_size=(img_width, img_height),\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    color_mode='grayscale',\n",
    "                                                    class_mode='raw')\n",
    "\n",
    "# Create the generator for loading the validation data from the folder\n",
    "valid_generator = val_test_datagen.flow_from_dataframe(dataframe=df[df['Usage']=='PublicTest'],\n",
    "                                                        directory=valid_path,\n",
    "                                                        x_col=\"Image name\",\n",
    "                                                        y_col=[\"neutral\", \"happiness\", \"surprise\", \"sadness\", \"anger\", \"disgust\", \"fear\"],\n",
    "                                                        target_size=(img_width, img_height),\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        color_mode='grayscale',\n",
    "                                                        class_mode='raw')\n",
    "\n",
    "# Create the generator for loading the test data from the folder\n",
    "test_generator = val_test_datagen.flow_from_dataframe(dataframe=df[df['Usage']=='PrivateTest'],\n",
    "                                                       directory=test_path,\n",
    "                                                       x_col=\"Image name\",\n",
    "                                                       y_col=[\"neutral\", \"happiness\", \"surprise\", \"sadness\", \"anger\", \"disgust\", \"fear\"],\n",
    "                                                       target_size=(img_width, img_height),\n",
    "                                                       batch_size=batch_size,\n",
    "                                                       color_mode='grayscale',\n",
    "                                                       class_mode='raw')\n",
    "\n",
    "# Define the model architecture\n",
    "num_features = 64\n",
    "input_shape = (48, 48, 1)\n",
    "classes = 7\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 1st stage\n",
    "model.add(Conv2D(num_features, kernel_size=(3, 3), input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation='relu'))\n",
    "model.add(Conv2D(num_features, kernel_size=(3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# 2nd stage\n",
    "model.add(Conv2D(num_features, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(num_features, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# 3rd stage\n",
    "model.add(Conv2D(2 * num_features, kernel_size=(3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation='relu'))\n",
    "model.add(Conv2D(2 * num_features, kernel_size=(3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation='relu'))\n",
    "\n",
    "# 4th stage\n",
    "model.add(Conv2D(2 * num_features, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(2 * num_features, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# 5th stage\n",
    "model.add(Conv2D(4 * num_features, kernel_size=(3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation='relu'))\n",
    "model.add(Conv2D(4 * num_features, kernel_size=(3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(activation='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected neural networks\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(classes, activation='softmax'))\n",
    "\n",
    "# # Creating an instance of the trained model\n",
    "# model = load_model('/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/Models/fer2013n_model_i.1.h5')\n",
    "\n",
    "# # Load the weights for your model\n",
    "# model.load_weights('/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/Models/fer2013n_model_weights_i.1.h5')\n",
    "\n",
    "#  Compile the model\n",
    "model.compile(loss=tf.keras.losses.binary_crossentropy,\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# define the ModelCheckpoint callback to save the model weights after each epoch\n",
    "checkpoint_callback = ModelCheckpoint('fer2013n_model_weights_i.1.h5', save_weights_only=True, save_best_only=True)\n",
    "\n",
    "#  Define the number of epochs to train the model\n",
    "epochs = 50\n",
    "\n",
    "#  Train the model\n",
    "history = model.fit(train_generator,\n",
    "          steps_per_epoch=train_generator.n // batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=valid_generator,\n",
    "          validation_steps=valid_generator.n // batch_size,\n",
    "          callbacks=[checkpoint_callback]\n",
    "          )\n",
    "\n",
    "#  Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(test_generator,\n",
    "                                     steps=test_generator.n // batch_size)\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Test loss:', test_loss)\n",
    "\n",
    "# Saving the model\n",
    "model.save('/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/Models/fer2013n_model_i.1.h5')\n",
    "model.save_weights('/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/Models/fer2013n_model_weights_i.1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O9VKGwzdL5RK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n50jOpeOgQ7q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iPXF0IU1RdLn",
    "outputId": "7e524b78-c2dd-4927-ce2f-fc4061c105dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28501 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py:1137: UserWarning: Found 60 invalid image filename(s) in x_col=\"Image name\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3579 validated image filenames.\n",
      "Found 3574 validated image filenames.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_10 (Conv2D)          (None, 46, 46, 64)        640       \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 46, 46, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 46, 46, 64)        0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 44, 44, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 44, 44, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 44, 44, 64)        0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 44, 44, 64)        0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 42, 42, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 40, 40, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 20, 20, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 18, 18, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 18, 18, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 18, 18, 128)       0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 16, 16, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 14, 14, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 12, 12, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 6, 6, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 4, 4, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 4, 4, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 2, 2, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 2, 2, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 2, 2, 256)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 7)                 7175      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,623,239\n",
      "Trainable params: 3,621,447\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 51/70\n",
      "445/445 [==============================] - 76s 153ms/step - loss: 0.2410 - accuracy: 0.6890 - val_loss: 0.1925 - val_accuracy: 0.7858\n",
      "Epoch 52/70\n",
      "445/445 [==============================] - 66s 147ms/step - loss: 0.2400 - accuracy: 0.6900 - val_loss: 0.1942 - val_accuracy: 0.7812\n",
      "Epoch 53/70\n",
      "445/445 [==============================] - 67s 150ms/step - loss: 0.2384 - accuracy: 0.6957 - val_loss: 0.1938 - val_accuracy: 0.7830\n",
      "Epoch 54/70\n",
      "445/445 [==============================] - 66s 147ms/step - loss: 0.2387 - accuracy: 0.6934 - val_loss: 0.1936 - val_accuracy: 0.7835\n",
      "Epoch 55/70\n",
      "445/445 [==============================] - 1082s 2s/step - loss: 0.2382 - accuracy: 0.6957 - val_loss: 0.1928 - val_accuracy: 0.7861\n",
      "Epoch 56/70\n",
      "445/445 [==============================] - 67s 149ms/step - loss: 0.2369 - accuracy: 0.6993 - val_loss: 0.1920 - val_accuracy: 0.7895\n",
      "Epoch 57/70\n",
      "445/445 [==============================] - 66s 148ms/step - loss: 0.2374 - accuracy: 0.6970 - val_loss: 0.1929 - val_accuracy: 0.7903\n",
      "Epoch 58/70\n",
      "445/445 [==============================] - 67s 149ms/step - loss: 0.2372 - accuracy: 0.6985 - val_loss: 0.1928 - val_accuracy: 0.7903\n",
      "Epoch 59/70\n",
      "445/445 [==============================] - 66s 147ms/step - loss: 0.2373 - accuracy: 0.6980 - val_loss: 0.1942 - val_accuracy: 0.7838\n",
      "Epoch 60/70\n",
      "445/445 [==============================] - 66s 148ms/step - loss: 0.2366 - accuracy: 0.6981 - val_loss: 0.1932 - val_accuracy: 0.7884\n",
      "Epoch 61/70\n",
      "445/445 [==============================] - 65s 146ms/step - loss: 0.2362 - accuracy: 0.7006 - val_loss: 0.1912 - val_accuracy: 0.7946\n",
      "Epoch 62/70\n",
      "445/445 [==============================] - 67s 149ms/step - loss: 0.2363 - accuracy: 0.6993 - val_loss: 0.1919 - val_accuracy: 0.7875\n",
      "Epoch 63/70\n",
      "445/445 [==============================] - 67s 150ms/step - loss: 0.2355 - accuracy: 0.6989 - val_loss: 0.1914 - val_accuracy: 0.7909\n",
      "Epoch 64/70\n",
      "445/445 [==============================] - 66s 148ms/step - loss: 0.2359 - accuracy: 0.7027 - val_loss: 0.1917 - val_accuracy: 0.7903\n",
      "Epoch 65/70\n",
      "445/445 [==============================] - 66s 147ms/step - loss: 0.2360 - accuracy: 0.6997 - val_loss: 0.1909 - val_accuracy: 0.7957\n",
      "Epoch 66/70\n",
      "445/445 [==============================] - 67s 151ms/step - loss: 0.2355 - accuracy: 0.7026 - val_loss: 0.1906 - val_accuracy: 0.7935\n",
      "Epoch 67/70\n",
      "445/445 [==============================] - 69s 155ms/step - loss: 0.2359 - accuracy: 0.7029 - val_loss: 0.1917 - val_accuracy: 0.7892\n",
      "Epoch 68/70\n",
      "445/445 [==============================] - 67s 151ms/step - loss: 0.2355 - accuracy: 0.7017 - val_loss: 0.1925 - val_accuracy: 0.7892\n",
      "Epoch 69/70\n",
      "445/445 [==============================] - 66s 148ms/step - loss: 0.2355 - accuracy: 0.7020 - val_loss: 0.1906 - val_accuracy: 0.7932\n",
      "Epoch 70/70\n",
      "445/445 [==============================] - 113s 253ms/step - loss: 0.2354 - accuracy: 0.7003 - val_loss: 0.1907 - val_accuracy: 0.7946\n",
      "55/55 [==============================] - 5s 93ms/step - loss: 0.1970 - accuracy: 0.7835\n",
      "Test accuracy: 0.7835227251052856\n",
      "Test loss: 0.19697602093219757\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Activation\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define the paths to the dataset folders and CSV file\n",
    "train_path = '/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/fer2013new/FER2013Train'\n",
    "valid_path = '/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/fer2013new/FER2013Valid'\n",
    "test_path = '/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/fer2013new/FER2013Test'\n",
    "csv_path = '/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/fer2013new/fer2013new1.csv'\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# # Remove rows with empty 'Image name' values\n",
    "# df.dropna(subset=['Image name'], inplace=True)\n",
    "\n",
    "\n",
    "# Define the parameters for the image data generator\n",
    "img_width = 48\n",
    "img_height = 48\n",
    "batch_size = 64\n",
    "\n",
    "# Create the image data generator for training data with data augmentation\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=30,\n",
    "                                   shear_range=0.3,\n",
    "                                   zoom_range=0.3,\n",
    "                                   width_shift_range=0.4,\n",
    "                                   height_shift_range=0.4,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "# Create the image data generator for validation and test data without data augmentation\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create the generator for loading the training data from the folder\n",
    "train_generator = train_datagen.flow_from_dataframe(dataframe=df[df['Usage']=='Training'],\n",
    "                                                    directory=train_path,\n",
    "                                                    x_col=\"Image name\",\n",
    "                                                    y_col=[\"neutral\", \"happiness\", \"surprise\", \"sadness\", \"anger\", \"disgust\", \"fear\"],\n",
    "                                                    target_size=(img_width, img_height),\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    color_mode='grayscale',\n",
    "                                                    class_mode='raw')\n",
    "\n",
    "# Create the generator for loading the validation data from the folder\n",
    "valid_generator = val_test_datagen.flow_from_dataframe(dataframe=df[df['Usage']=='PublicTest'],\n",
    "                                                        directory=valid_path,\n",
    "                                                        x_col=\"Image name\",\n",
    "                                                        y_col=[\"neutral\", \"happiness\", \"surprise\", \"sadness\", \"anger\", \"disgust\", \"fear\"],\n",
    "                                                        target_size=(img_width, img_height),\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        color_mode='grayscale',\n",
    "                                                        class_mode='raw')\n",
    "\n",
    "# Create the generator for loading the test data from the folder\n",
    "test_generator = val_test_datagen.flow_from_dataframe(dataframe=df[df['Usage']=='PrivateTest'],\n",
    "                                                       directory=test_path,\n",
    "                                                       x_col=\"Image name\",\n",
    "                                                       y_col=[\"neutral\", \"happiness\", \"surprise\", \"sadness\", \"anger\", \"disgust\", \"fear\"],\n",
    "                                                       target_size=(img_width, img_height),\n",
    "                                                       batch_size=batch_size,\n",
    "                                                       color_mode='grayscale',\n",
    "                                                       class_mode='raw')\n",
    "\n",
    "# # Define the model architecture\n",
    "# num_features = 64\n",
    "# input_shape = (48, 48, 1)\n",
    "# classes = 7\n",
    "\n",
    "# model = Sequential()\n",
    "\n",
    "# # 1st stage\n",
    "# model.add(Conv2D(num_features, kernel_size=(3, 3), input_shape=input_shape))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation(activation='relu'))\n",
    "# model.add(Conv2D(num_features, kernel_size=(3, 3)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation(activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "# # 2nd stage\n",
    "# model.add(Conv2D(num_features, (3, 3), activation='relu'))\n",
    "# model.add(Conv2D(num_features, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # 3rd stage\n",
    "# model.add(Conv2D(2 * num_features, kernel_size=(3, 3)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation(activation='relu'))\n",
    "# model.add(Conv2D(2 * num_features, kernel_size=(3, 3)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation(activation='relu'))\n",
    "\n",
    "# # 4th stage\n",
    "# model.add(Conv2D(2 * num_features, (3, 3), activation='relu'))\n",
    "# model.add(Conv2D(2 * num_features, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# # 5th stage\n",
    "# model.add(Conv2D(4 * num_features, kernel_size=(3, 3)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation(activation='relu'))\n",
    "# model.add(Conv2D(4 * num_features, kernel_size=(3, 3)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation(activation='relu'))\n",
    "\n",
    "# model.add(Flatten())\n",
    "\n",
    "# # Fully connected neural networks\n",
    "# model.add(Dense(1024, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(1024, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Dense(classes, activation='softmax'))\n",
    "\n",
    "# Creating an instance of the trained model\n",
    "model = load_model('/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/Models/fer2013n_model_i.1.h5')\n",
    "\n",
    "# Load the weights for your model\n",
    "model.load_weights('/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/Models/fer2013n_model_weights_i.1.h5')\n",
    "\n",
    "#  Compile the model\n",
    "model.compile(loss=tf.keras.losses.binary_crossentropy,\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),\n",
    "metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# define the ModelCheckpoint callback to save the model weights after each epoch\n",
    "checkpoint_callback = ModelCheckpoint('fer2013n_model_weights_i.2.h5', save_weights_only=True, save_best_only=True)\n",
    "\n",
    "# #  Define the number of epochs to train the model\n",
    "# epochs = 50\n",
    "\n",
    "#  Train the model\n",
    "history = model.fit(train_generator,\n",
    "          steps_per_epoch=train_generator.n // batch_size,\n",
    "          epochs=70,\n",
    "          initial_epoch=50,\n",
    "          validation_data=valid_generator,\n",
    "          validation_steps=valid_generator.n // batch_size,\n",
    "          callbacks=[checkpoint_callback]\n",
    "          )\n",
    "\n",
    "#  Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(test_generator,\n",
    "                                     steps=test_generator.n // batch_size)\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Test loss:', test_loss)\n",
    "\n",
    "# Saving the model\n",
    "model.save('/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/Models/fer2013n_model_i.2.h5')\n",
    "model.save_weights('/content/drive/MyDrive/Colab Notebooks/NLP - Keerthana mam/Models/fer2013n_model_weights_i.2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "u3PLqDCKWEA4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 33s 33s/step\n",
      "[[1.5736304e-04 9.9977404e-01 9.3155895e-06 6.4082960e-06 1.9069141e-05\n",
      "  2.8513588e-05 5.1648449e-06]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the image you want to predict\n",
    "img_path = 'test.jpg'\n",
    "img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "img_width = 48\n",
    "img_height = 48\n",
    "\n",
    "# Resize the image to the same dimensions as the training data\n",
    "img = cv2.resize(img, (img_width, img_height))\n",
    "\n",
    "# Reshape the image to match the input shape of the model\n",
    "img = img.reshape(1, img_width, img_height, 1)\n",
    "\n",
    "# Normalize the pixel values to be between 0 and 1\n",
    "img = img / 255.0\n",
    "\n",
    "model = load_model('Models/fer2013n_model_i.2.h5')\n",
    "\n",
    "# Predict the emotion probabilities for the image using the trained model\n",
    "emotions_prob = model.predict(img)\n",
    "\n",
    "# Print the predicted probabilities for each emotion\n",
    "print(emotions_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00015736304339952767, 0.9997740387916565, 9.315589522884693e-06, 6.408296030713245e-06, 1.906914076243993e-05, 2.8513588404166512e-05, 5.164844878891017e-06]\n"
     ]
    }
   ],
   "source": [
    "print(emotions_prob[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "emotions = [\"neutral\", \"happiness\", \"surprise\", \"sadness\", \"anger\", \"disgust\", \"fear\"]\n",
    "emotion_probs = [0.00015736304339952767, 0.9997740387916565, 9.315589522884693e-06, 6.408296030713245e-06, 1.906914076243993e-05, 2.8513588404166512e-05, 5.164844878891017e-06]\n",
    "emotion_probs = [prob*100 for prob in emotion_probs]\n",
    "\n",
    "# Set bar color based on emotion\n",
    "colors = ['#FF5733', '#6A5ACD', '#800000', '#FFFF00', '#A9A9A9', '#1E90FF', '#FFA07A']\n",
    "\n",
    "# Create horizontal bar chart\n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "y_pos = np.arange(len(emotions))\n",
    "ax.barh(y_pos, emotion_probs, align='center', color=colors)\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(emotions)\n",
    "ax.invert_yaxis()  # labels read top-to-bottom\n",
    "ax.set_xlabel('Probability')\n",
    "ax.set_title('Emotion Classification Probabilities')\n",
    "\n",
    "# Add probability values as labels above each bar\n",
    "for i, prob in enumerate(emotion_probs):\n",
    "    ax.text(prob+1, i, str(round(prob, 3)), color='black', va='center', fontweight='bold')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
